{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76f37b-7a33-4ad3-a357-212db7fb7caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! Welcome to YellowSquare Hostel's chat. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can I bring a pet?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I'm sorry, but we do not allow pets at Yellow Hostel. Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"Your Api Key\")\n",
    "\n",
    "# Initial system message\n",
    "initial_info = \"I want you to reply to the messages of a customer of a hostel. Please keep the chat short. Here is the hostel information: Yellow Hostel has redefined the meaning of what a hostel is. YellowSquare is no longer just a place to rest in a bunk bed—it’s where you can work, socialize, and enjoy activities like live bands, shopping tours, gourmet cooking classes, and more. Our Concierge Bar is perfect for meeting people, relaxing, and enjoying great food and drinks. The coworking space allows you to work in a dedicated area while exploring Rome. The hostel follows all COVID-19 safety measures. If you love to party, socialize, and meet an international crowd, you’ll love it here! For a more relaxed stay, book a private room with amenities like air conditioning, ensuite bathrooms, and Wi-Fi. We offer free city maps, tours, and a 24/7 hot shower. Guests must be between 18-45 years old, with specific rules for minors. Check our Terms & Conditions for more details.\"\n",
    "\n",
    "# Initial chatbot message\n",
    "print(\"AI: Hello! Welcome to YellowSquare Hostel's chat. How can I assist you today?\")\n",
    "\n",
    "# Conversation history with system message\n",
    "messages = [{\"role\": \"system\", \"content\": initial_info}]\n",
    "\n",
    "# Message limit\n",
    "message_count = 0\n",
    "MAX_MESSAGES = 20\n",
    "\n",
    "while message_count < MAX_MESSAGES:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"end\":\n",
    "        print(\"AI: Ending chat. Have a great day!\")\n",
    "        break\n",
    "\n",
    "    # Add user message to history\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Stream response from OpenAI API\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    print(\"AI: \", end=\"\")\n",
    "    response_text = \"\"\n",
    "\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            response_text += chunk.choices[0].delta.content\n",
    "\n",
    "    print()  # Newline after response\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_text})  # Store AI response\n",
    "    \n",
    "    message_count += 1\n",
    "\n",
    "# Message limit reached\n",
    "if message_count >= MAX_MESSAGES:\n",
    "    print(\"AI: You've reached the maximum limit of 20 messages. If you need more help, feel free to restart the chat. Have a great day!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
